# GSD: Build Orchestration ATLAS (The Real One)

**Priority:** CRITICAL - Core Infrastructure  
**Estimated Time:** 4-6 hours  
**Created:** 2026-01-18  
**Status:** Ready for execution

---

## Problem Statement

ATLAS (port 8007) - the orchestration engine - **does not exist**. The code at `/control-plane/agents/atlas/atlas.py` is actually ATLAS-INFRA (port 8208), an infrastructure advisory agent. This has caused repeated "ATLAS offline" errors because there's literally nothing running on port 8007.

SENTINEL tries to route orchestration requests to `http://atlas:8007` â†’ Nothing responds â†’ "No healthy orchestration engine available"

---

## Success Criteria

- [ ] ATLAS running on port 8007, responding to health checks
- [ ] All 6 chains from agent-registry.yaml executable
- [ ] Parallel batch processing working (5+ concurrent chains)
- [ ] Cost tracking per chain execution
- [ ] SENTINEL successfully routing to ATLAS
- [ ] HEPHAESTUS MCP `orchestrate` tool working
- [ ] All tests passing

---

## Architecture Overview

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         OLYMPUS                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚
â”‚  â”‚   SENTINEL   â”‚â”€â”€â”€â–¶â”‚    ATLAS     â”‚â”€â”€â”€â–¶â”‚   AGENTS     â”‚      â”‚
â”‚  â”‚  (Router)    â”‚    â”‚ (Orchestrator)â”‚    â”‚ (Executors)  â”‚      â”‚
â”‚  â”‚   :8006      â”‚    â”‚    :8007     â”‚    â”‚  :8008-8300  â”‚      â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚
â”‚         â”‚                   â”‚                    â”‚              â”‚
â”‚         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â”‚
â”‚                             â”‚                                    â”‚
â”‚                      â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”                            â”‚
â”‚                      â”‚  Event Bus  â”‚                            â”‚
â”‚                      â”‚    :8099    â”‚                            â”‚
â”‚                      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Section 1: Create ATLAS Directory Structure

```bash
# Create proper ATLAS orchestration directory
mkdir -p /opt/leveredge/control-plane/agents/atlas-orchestrator
cd /opt/leveredge/control-plane/agents/atlas-orchestrator

# Move the old atlas.py to atlas-infra where it belongs
mv /opt/leveredge/control-plane/agents/atlas/atlas.py /opt/leveredge/control-plane/agents/atlas-infra/atlas_infra_full.py 2>/dev/null || true
```

---

## Section 2: Core ATLAS Orchestrator

Create `/opt/leveredge/control-plane/agents/atlas-orchestrator/atlas.py`:

```python
#!/usr/bin/env python3
"""
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                              ATLAS                                             â•‘
â•‘                    The Titan Who Holds Up The Heavens                          â•‘
â•‘                                                                                â•‘
â•‘  Port: 8007                                                                    â•‘
â•‘                                                                                â•‘
â•‘  The orchestration engine for LeverEdge. Executes chains, coordinates         â•‘
â•‘  agents, handles parallel batch processing, and tracks costs.                  â•‘
â•‘                                                                                â•‘
â•‘  CAPABILITIES:                                                                 â•‘
â•‘  â€¢ Chain execution (sequential and parallel steps)                            â•‘
â•‘  â€¢ Multi-agent coordination                                                    â•‘
â•‘  â€¢ Parallel batch processing with concurrency control                         â•‘
â•‘  â€¢ Cost tracking per execution                                                â•‘
â•‘  â€¢ Real-time status updates via Event Bus                                     â•‘
â•‘  â€¢ Graceful error handling and rollback                                       â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
"""

import asyncio
import os
import sys
import json
import yaml
import uuid
import re
from datetime import datetime, date
from typing import Dict, Optional, List, Any, Union
from dataclasses import dataclass, field, asdict
from enum import Enum
from pathlib import Path
import traceback

import httpx
from fastapi import FastAPI, HTTPException, BackgroundTasks
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel, Field

# Add shared modules
sys.path.append('/opt/leveredge/control-plane/shared')
try:
    from cost_tracker import CostTracker, log_llm_usage
except ImportError:
    # Fallback if cost_tracker not available
    class CostTracker:
        def __init__(self, agent): pass
        async def log(self, *args, **kwargs): pass
    async def log_llm_usage(*args, **kwargs): pass

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# CONFIGURATION
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ATLAS_PORT = 8007
REGISTRY_PATH = Path(os.getenv("REGISTRY_PATH", "/opt/leveredge/config/agent-registry.yaml"))
EVENT_BUS_URL = os.getenv("EVENT_BUS_URL", "http://localhost:8099")
HERMES_URL = os.getenv("HERMES_URL", "http://localhost:8014")

# Launch tracking
LAUNCH_DATE = date(2026, 3, 1)

# Execution limits
MAX_CHAIN_DEPTH = 10
MAX_PARALLEL_TASKS = 20
DEFAULT_TIMEOUT = 180  # seconds
MAX_BATCH_SIZE = 100

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ENUMS AND DATA CLASSES
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class ExecutionStatus(str, Enum):
    PENDING = "pending"
    RUNNING = "running"
    COMPLETED = "completed"
    FAILED = "failed"
    CANCELLED = "cancelled"
    PARTIAL = "partial"  # Some steps succeeded, some failed


class StepStatus(str, Enum):
    PENDING = "pending"
    RUNNING = "running"
    COMPLETED = "completed"
    FAILED = "failed"
    SKIPPED = "skipped"


@dataclass
class StepResult:
    step_id: str
    agent: str
    action: str
    status: StepStatus
    output: Any = None
    error: Optional[str] = None
    duration_ms: int = 0
    cost: float = 0.0
    started_at: Optional[str] = None
    completed_at: Optional[str] = None


@dataclass
class ExecutionResult:
    intent_id: str
    chain_name: Optional[str]
    status: ExecutionStatus
    step_results: List[StepResult] = field(default_factory=list)
    final_output: Any = None
    total_cost: float = 0.0
    total_duration_ms: int = 0
    started_at: Optional[str] = None
    completed_at: Optional[str] = None
    error: Optional[str] = None


@dataclass
class BatchTask:
    task_id: str
    chain_name: Optional[str]
    steps: Optional[List[dict]]
    input: dict
    status: ExecutionStatus = ExecutionStatus.PENDING
    result: Optional[ExecutionResult] = None


@dataclass
class BatchExecution:
    batch_id: str
    tasks: List[BatchTask]
    concurrency: int
    status: ExecutionStatus = ExecutionStatus.PENDING
    completed: int = 0
    failed: int = 0
    total_cost: float = 0.0
    started_at: Optional[str] = None
    completed_at: Optional[str] = None
    callback_url: Optional[str] = None


# In-memory storage for batch executions
batch_store: Dict[str, BatchExecution] = {}

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# REGISTRY LOADER
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class RegistryLoader:
    """Loads and caches the agent registry."""
    
    def __init__(self):
        self._registry = None
        self._last_loaded = None
        self._cache_ttl = 60  # Reload every 60 seconds
    
    def load(self) -> dict:
        """Load registry, using cache if fresh."""
        now = datetime.utcnow()
        
        if self._registry and self._last_loaded:
            age = (now - self._last_loaded).total_seconds()
            if age < self._cache_ttl:
                return self._registry
        
        try:
            with open(REGISTRY_PATH) as f:
                self._registry = yaml.safe_load(f)
                self._last_loaded = now
                return self._registry
        except Exception as e:
            if self._registry:
                return self._registry  # Return stale cache
            raise RuntimeError(f"Failed to load registry: {e}")
    
    def get_chain(self, name: str) -> Optional[dict]:
        """Get chain definition by name."""
        registry = self.load()
        return registry.get("chains", {}).get(name)
    
    def get_agent(self, name: str) -> Optional[dict]:
        """Get agent definition by name."""
        registry = self.load()
        return registry.get("agents", {}).get(name.lower())
    
    def list_chains(self) -> List[dict]:
        """List all available chains."""
        registry = self.load()
        chains = registry.get("chains", {})
        return [
            {
                "name": name,
                "description": chain.get("description", ""),
                "complexity": chain.get("complexity", "simple"),
                "estimated_cost": chain.get("estimated_cost", 0),
                "estimated_time_ms": chain.get("estimated_time_ms", 0)
            }
            for name, chain in chains.items()
        ]
    
    def list_agents(self) -> List[dict]:
        """List all available agents."""
        registry = self.load()
        agents = registry.get("agents", {})
        return [
            {
                "name": name,
                "description": agent.get("description", ""),
                "category": agent.get("category", ""),
                "llm_powered": agent.get("llm_powered", False),
                "url": agent.get("connection", {}).get("url", ""),
                "actions": list(agent.get("actions", {}).keys())
            }
            for name, agent in agents.items()
        ]


registry = RegistryLoader()

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# TEMPLATE ENGINE
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class TemplateEngine:
    """Simple template engine for chain step inputs."""
    
    @staticmethod
    def render(template: str, context: dict) -> str:
        """Render a template string with context variables."""
        if not template:
            return template
        
        result = template
        
        # Handle {{variable}} syntax
        pattern = r'\{\{([^}]+)\}\}'
        
        def replace_var(match):
            path = match.group(1).strip()
            value = TemplateEngine._resolve_path(path, context)
            if value is None:
                return match.group(0)  # Keep original if not found
            if isinstance(value, (dict, list)):
                return json.dumps(value)
            return str(value)
        
        result = re.sub(pattern, replace_var, result)
        return result
    
    @staticmethod
    def render_dict(obj: Any, context: dict) -> Any:
        """Recursively render templates in a dict/list structure."""
        if isinstance(obj, str):
            return TemplateEngine.render(obj, context)
        elif isinstance(obj, dict):
            return {k: TemplateEngine.render_dict(v, context) for k, v in obj.items()}
        elif isinstance(obj, list):
            return [TemplateEngine.render_dict(item, context) for item in obj]
        return obj
    
    @staticmethod
    def _resolve_path(path: str, context: dict) -> Any:
        """Resolve a dotted path like 'steps.research.output.data'."""
        parts = path.split('.')
        current = context
        
        for part in parts:
            if isinstance(current, dict):
                # Handle array index like 'items[0]'
                if '[' in part:
                    key, idx = part.split('[')
                    idx = int(idx.rstrip(']'))
                    current = current.get(key, [])
                    if isinstance(current, list) and len(current) > idx:
                        current = current[idx]
                    else:
                        return None
                else:
                    current = current.get(part)
            else:
                return None
            
            if current is None:
                return None
        
        return current


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# AGENT CALLER
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class AgentCaller:
    """Handles calling individual agents."""
    
    def __init__(self):
        self.client = httpx.AsyncClient(timeout=DEFAULT_TIMEOUT)
    
    async def call(
        self,
        agent_name: str,
        action: str,
        params: dict,
        timeout: Optional[int] = None
    ) -> dict:
        """Call an agent action and return the result."""
        
        agent_config = registry.get_agent(agent_name)
        if not agent_config:
            raise ValueError(f"Agent '{agent_name}' not found in registry")
        
        action_config = agent_config.get("actions", {}).get(action)
        if not action_config:
            raise ValueError(f"Action '{action}' not found for agent '{agent_name}'")
        
        # Build URL
        base_url = agent_config["connection"]["url"]
        endpoint = action_config["endpoint"]
        
        # Handle path parameters like /framework/{name}
        for key, value in params.items():
            if f"{{{key}}}" in endpoint:
                endpoint = endpoint.replace(f"{{{key}}}", str(value))
        
        url = f"{base_url}{endpoint}"
        method = action_config.get("method", "POST").upper()
        
        # Determine timeout
        action_timeout = timeout or action_config.get("timeout_ms", 60000) / 1000
        
        try:
            if method == "GET":
                response = await self.client.get(url, params=params, timeout=action_timeout)
            else:
                response = await self.client.post(url, json=params, timeout=action_timeout)
            
            response.raise_for_status()
            return response.json()
            
        except httpx.TimeoutException:
            raise TimeoutError(f"Agent '{agent_name}/{action}' timed out after {action_timeout}s")
        except httpx.HTTPStatusError as e:
            raise RuntimeError(f"Agent '{agent_name}/{action}' returned {e.response.status_code}: {e.response.text}")
        except Exception as e:
            raise RuntimeError(f"Failed to call '{agent_name}/{action}': {str(e)}")
    
    async def close(self):
        await self.client.aclose()


agent_caller = AgentCaller()

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# CHAIN EXECUTOR
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class ChainExecutor:
    """Executes chains with step-by-step processing."""
    
    def __init__(self):
        self.template = TemplateEngine()
    
    async def execute(
        self,
        chain_name: Optional[str] = None,
        steps: Optional[List[dict]] = None,
        input_data: dict = None,
        options: dict = None
    ) -> ExecutionResult:
        """Execute a chain (by name or ad-hoc steps)."""
        
        intent_id = str(uuid.uuid4())
        started_at = datetime.utcnow()
        
        result = ExecutionResult(
            intent_id=intent_id,
            chain_name=chain_name,
            status=ExecutionStatus.RUNNING,
            started_at=started_at.isoformat()
        )
        
        try:
            # Get chain definition
            if chain_name:
                chain_def = registry.get_chain(chain_name)
                if not chain_def:
                    raise ValueError(f"Chain '{chain_name}' not found")
                steps = chain_def.get("steps", [])
            
            if not steps:
                raise ValueError("No steps provided")
            
            # Build execution context
            context = {
                "input": input_data or {},
                "steps": {},
                "options": options or {}
            }
            
            # Execute steps
            for step in steps:
                step_result = await self._execute_step(step, context)
                result.step_results.append(step_result)
                result.total_cost += step_result.cost
                
                # Store step output in context for subsequent steps
                context["steps"][step["id"]] = {
                    "output": step_result.output,
                    "status": step_result.status.value
                }
                
                # Check for failure
                if step_result.status == StepStatus.FAILED:
                    # Check if step is optional
                    if not step.get("optional", False):
                        result.status = ExecutionStatus.FAILED
                        result.error = f"Step '{step['id']}' failed: {step_result.error}"
                        break
            
            # Determine final status
            if result.status != ExecutionStatus.FAILED:
                failed_count = sum(1 for sr in result.step_results if sr.status == StepStatus.FAILED)
                if failed_count > 0:
                    result.status = ExecutionStatus.PARTIAL
                else:
                    result.status = ExecutionStatus.COMPLETED
            
            # Apply output template if defined
            chain_def = registry.get_chain(chain_name) if chain_name else {}
            output_template = chain_def.get("output_template")
            if output_template:
                result.final_output = self.template.render(output_template, context)
            else:
                # Use last step's output
                if result.step_results:
                    result.final_output = result.step_results[-1].output
            
        except Exception as e:
            result.status = ExecutionStatus.FAILED
            result.error = str(e)
            traceback.print_exc()
        
        finally:
            completed_at = datetime.utcnow()
            result.completed_at = completed_at.isoformat()
            result.total_duration_ms = int((completed_at - started_at).total_seconds() * 1000)
            
            # Log to event bus
            await self._log_execution(result)
        
        return result
    
    async def _execute_step(self, step: dict, context: dict) -> StepResult:
        """Execute a single step."""
        
        step_id = step.get("id", str(uuid.uuid4()))
        started_at = datetime.utcnow()
        
        result = StepResult(
            step_id=step_id,
            agent=step.get("agent", ""),
            action=step.get("action", ""),
            status=StepStatus.RUNNING,
            started_at=started_at.isoformat()
        )
        
        try:
            # Check condition
            condition = step.get("condition")
            if condition and not self._evaluate_condition(condition, context):
                result.status = StepStatus.SKIPPED
                result.output = {"skipped": True, "reason": "Condition not met"}
                return result
            
            # Handle parallel substeps
            if step.get("type") == "parallel":
                result = await self._execute_parallel_substeps(step, context, result)
                return result
            
            # Build params from step definition
            params = {}
            
            # Add params from step config
            for param in step.get("params", {}):
                if isinstance(param, dict):
                    param_name = param.get("name")
                    param_value = param.get("value") or param.get("default")
                else:
                    continue
                if param_value:
                    params[param_name] = self.template.render_dict(param_value, context)
            
            # Handle input_template
            input_template = step.get("input_template")
            if input_template:
                rendered = self.template.render(input_template, context)
                # If the action expects a 'message' or specific param
                action_config = registry.get_agent(step["agent"])
                if action_config:
                    action_def = action_config.get("actions", {}).get(step["action"], {})
                    action_params = action_def.get("params", [])
                    # Find the first required string param
                    for p in action_params:
                        if p.get("required") and p.get("type") == "string":
                            params[p["name"]] = rendered
                            break
                    else:
                        params["message"] = rendered  # fallback
            
            # Direct params override
            if step.get("params") and isinstance(step["params"], dict):
                for k, v in step["params"].items():
                    params[k] = self.template.render_dict(v, context)
            
            # Call the agent
            output = await agent_caller.call(
                agent_name=step["agent"],
                action=step["action"],
                params=params,
                timeout=step.get("timeout_ms", None)
            )
            
            result.status = StepStatus.COMPLETED
            result.output = output
            
            # Extract cost if present
            if isinstance(output, dict):
                result.cost = output.get("cost", 0) or output.get("total_cost", 0) or 0
            
        except Exception as e:
            result.status = StepStatus.FAILED
            result.error = str(e)
            traceback.print_exc()
        
        finally:
            completed_at = datetime.utcnow()
            result.completed_at = completed_at.isoformat()
            result.duration_ms = int((completed_at - started_at).total_seconds() * 1000)
        
        return result
    
    async def _execute_parallel_substeps(
        self,
        step: dict,
        context: dict,
        parent_result: StepResult
    ) -> StepResult:
        """Execute parallel substeps concurrently."""
        
        substeps = step.get("substeps", [])
        if not substeps:
            parent_result.status = StepStatus.COMPLETED
            parent_result.output = {}
            return parent_result
        
        # Create tasks for all substeps
        async def run_substep(substep):
            return await self._execute_step(substep, context)
        
        tasks = [run_substep(s) for s in substeps]
        substep_results = await asyncio.gather(*tasks, return_exceptions=True)
        
        # Aggregate results
        outputs = {}
        total_cost = 0
        all_completed = True
        
        for substep, result in zip(substeps, substep_results):
            substep_id = substep.get("id", "unknown")
            
            if isinstance(result, Exception):
                outputs[substep_id] = {"error": str(result)}
                all_completed = False
            elif isinstance(result, StepResult):
                outputs[substep_id] = {"output": result.output, "status": result.status.value}
                total_cost += result.cost
                if result.status == StepStatus.FAILED:
                    all_completed = False
        
        parent_result.output = outputs
        parent_result.cost = total_cost
        parent_result.status = StepStatus.COMPLETED if all_completed else StepStatus.FAILED
        
        # Store parallel results in context
        context["steps"][step["id"]] = outputs
        
        return parent_result
    
    def _evaluate_condition(self, condition: dict, context: dict) -> bool:
        """Evaluate a step condition."""
        field_path = condition.get("field", "")
        operator = condition.get("operator", "exists")
        expected = condition.get("value")
        
        actual = self.template._resolve_path(field_path, context)
        
        if operator == "exists":
            return actual is not None
        elif operator == "eq":
            return actual == expected
        elif operator == "ne":
            return actual != expected
        elif operator == "contains":
            return expected in str(actual) if actual else False
        elif operator == "gt":
            return float(actual) > float(expected) if actual else False
        elif operator == "lt":
            return float(actual) < float(expected) if actual else False
        
        return True
    
    async def _log_execution(self, result: ExecutionResult):
        """Log execution to event bus."""
        try:
            async with httpx.AsyncClient() as client:
                await client.post(
                    f"{EVENT_BUS_URL}/publish",
                    json={
                        "event_type": "chain_execution_completed",
                        "source": "ATLAS",
                        "data": {
                            "intent_id": result.intent_id,
                            "chain_name": result.chain_name,
                            "status": result.status.value,
                            "total_cost": result.total_cost,
                            "duration_ms": result.total_duration_ms,
                            "step_count": len(result.step_results)
                        }
                    },
                    timeout=2.0
                )
        except:
            pass  # Don't fail execution due to logging failure


chain_executor = ChainExecutor()

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# BATCH EXECUTOR
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class BatchExecutor:
    """Handles parallel batch execution of multiple chains."""
    
    async def execute_batch(
        self,
        tasks: List[dict],
        concurrency: int = 5,
        callback_url: Optional[str] = None
    ) -> str:
        """Start a batch execution and return batch_id."""
        
        batch_id = str(uuid.uuid4())
        
        # Create batch tasks
        batch_tasks = [
            BatchTask(
                task_id=str(uuid.uuid4()),
                chain_name=t.get("chain") or t.get("chain_name"),
                steps=t.get("steps"),
                input=t.get("input", {})
            )
            for t in tasks[:MAX_BATCH_SIZE]
        ]
        
        batch = BatchExecution(
            batch_id=batch_id,
            tasks=batch_tasks,
            concurrency=min(concurrency, MAX_PARALLEL_TASKS),
            status=ExecutionStatus.RUNNING,
            started_at=datetime.utcnow().isoformat(),
            callback_url=callback_url
        )
        
        batch_store[batch_id] = batch
        
        # Start background execution
        asyncio.create_task(self._run_batch(batch))
        
        return batch_id
    
    async def _run_batch(self, batch: BatchExecution):
        """Run batch tasks with concurrency control."""
        
        semaphore = asyncio.Semaphore(batch.concurrency)
        
        async def run_task(task: BatchTask):
            async with semaphore:
                task.status = ExecutionStatus.RUNNING
                try:
                    result = await chain_executor.execute(
                        chain_name=task.chain_name,
                        steps=task.steps,
                        input_data=task.input
                    )
                    task.result = result
                    task.status = result.status
                    batch.total_cost += result.total_cost
                    
                    if result.status == ExecutionStatus.COMPLETED:
                        batch.completed += 1
                    else:
                        batch.failed += 1
                        
                except Exception as e:
                    task.status = ExecutionStatus.FAILED
                    task.result = ExecutionResult(
                        intent_id=str(uuid.uuid4()),
                        chain_name=task.chain_name,
                        status=ExecutionStatus.FAILED,
                        error=str(e)
                    )
                    batch.failed += 1
        
        # Run all tasks
        await asyncio.gather(*[run_task(t) for t in batch.tasks])
        
        # Update batch status
        batch.completed_at = datetime.utcnow().isoformat()
        if batch.failed == 0:
            batch.status = ExecutionStatus.COMPLETED
        elif batch.completed == 0:
            batch.status = ExecutionStatus.FAILED
        else:
            batch.status = ExecutionStatus.PARTIAL
        
        # Call callback if provided
        if batch.callback_url:
            try:
                async with httpx.AsyncClient() as client:
                    await client.post(
                        batch.callback_url,
                        json={
                            "batch_id": batch.batch_id,
                            "status": batch.status.value,
                            "completed": batch.completed,
                            "failed": batch.failed,
                            "total_cost": batch.total_cost
                        },
                        timeout=10.0
                    )
            except:
                pass
        
        # Log completion
        await self._log_batch_completion(batch)
    
    async def _log_batch_completion(self, batch: BatchExecution):
        """Log batch completion to event bus."""
        try:
            async with httpx.AsyncClient() as client:
                await client.post(
                    f"{EVENT_BUS_URL}/publish",
                    json={
                        "event_type": "batch_execution_completed",
                        "source": "ATLAS",
                        "data": {
                            "batch_id": batch.batch_id,
                            "status": batch.status.value,
                            "completed": batch.completed,
                            "failed": batch.failed,
                            "total_tasks": len(batch.tasks),
                            "total_cost": batch.total_cost
                        }
                    },
                    timeout=2.0
                )
        except:
            pass
    
    def get_batch_status(self, batch_id: str) -> Optional[dict]:
        """Get batch execution status."""
        batch = batch_store.get(batch_id)
        if not batch:
            return None
        
        return {
            "batch_id": batch.batch_id,
            "status": batch.status.value,
            "completed": batch.completed,
            "failed": batch.failed,
            "pending": len(batch.tasks) - batch.completed - batch.failed,
            "running": sum(1 for t in batch.tasks if t.status == ExecutionStatus.RUNNING),
            "total_tasks": len(batch.tasks),
            "progress_percent": round((batch.completed + batch.failed) / len(batch.tasks) * 100, 1),
            "total_cost": batch.total_cost,
            "started_at": batch.started_at,
            "completed_at": batch.completed_at
        }
    
    def get_batch_results(self, batch_id: str) -> Optional[dict]:
        """Get full batch results."""
        batch = batch_store.get(batch_id)
        if not batch:
            return None
        
        return {
            "batch_id": batch.batch_id,
            "status": batch.status.value,
            "tasks": [
                {
                    "task_id": t.task_id,
                    "chain_name": t.chain_name,
                    "status": t.status.value,
                    "result": asdict(t.result) if t.result else None
                }
                for t in batch.tasks
            ],
            "total_cost": batch.total_cost,
            "started_at": batch.started_at,
            "completed_at": batch.completed_at
        }
    
    def list_batches(self, limit: int = 20, active_only: bool = False) -> List[dict]:
        """List recent batch executions."""
        batches = list(batch_store.values())
        
        if active_only:
            batches = [b for b in batches if b.status == ExecutionStatus.RUNNING]
        
        # Sort by started_at descending
        batches.sort(key=lambda b: b.started_at or "", reverse=True)
        
        return [self.get_batch_status(b.batch_id) for b in batches[:limit]]


batch_executor = BatchExecutor()

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# PYDANTIC MODELS
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class ExecuteRequest(BaseModel):
    chain_name: Optional[str] = None
    steps: Optional[List[dict]] = None
    input: dict = Field(default_factory=dict)
    options: Optional[dict] = None


class BatchExecuteRequest(BaseModel):
    tasks: List[dict]
    concurrency: int = Field(default=5, ge=1, le=MAX_PARALLEL_TASKS)
    callback_url: Optional[str] = None


class DirectCallRequest(BaseModel):
    agent: str
    action: str
    params: dict = Field(default_factory=dict)

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# FASTAPI APPLICATION
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

app = FastAPI(
    title="ATLAS - Orchestration Engine",
    description="The Titan who holds up the heavens. Chain execution and multi-agent coordination.",
    version="2.0.0"
)

app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_methods=["*"],
    allow_headers=["*"],
)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# HEALTH & STATUS
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

@app.get("/health")
async def health():
    """Health check endpoint."""
    today = date.today()
    days_to_launch = (LAUNCH_DATE - today).days
    
    return {
        "status": "healthy",
        "agent": "ATLAS",
        "role": "Orchestration Engine",
        "port": ATLAS_PORT,
        "version": "2.0.0",
        "timestamp": datetime.utcnow().isoformat(),
        "days_to_launch": days_to_launch,
        "registry_loaded": registry._registry is not None,
        "active_batches": sum(1 for b in batch_store.values() if b.status == ExecutionStatus.RUNNING)
    }


@app.get("/status")
async def status():
    """Detailed status."""
    chains = registry.list_chains()
    agents = registry.list_agents()
    
    return {
        "atlas": {
            "status": "healthy",
            "version": "2.0.0",
            "uptime": "running"
        },
        "registry": {
            "chains_count": len(chains),
            "agents_count": len(agents),
            "last_loaded": registry._last_loaded.isoformat() if registry._last_loaded else None
        },
        "batches": {
            "active": sum(1 for b in batch_store.values() if b.status == ExecutionStatus.RUNNING),
            "total": len(batch_store)
        },
        "timestamp": datetime.utcnow().isoformat()
    }


@app.get("/metrics")
async def metrics():
    """Prometheus-compatible metrics."""
    active_batches = sum(1 for b in batch_store.values() if b.status == ExecutionStatus.RUNNING)
    total_batches = len(batch_store)
    completed_batches = sum(1 for b in batch_store.values() if b.status == ExecutionStatus.COMPLETED)
    
    return f"""# HELP atlas_active_batches Number of currently running batch executions
# TYPE atlas_active_batches gauge
atlas_active_batches {active_batches}

# HELP atlas_total_batches Total number of batch executions
# TYPE atlas_total_batches counter
atlas_total_batches {total_batches}

# HELP atlas_completed_batches Number of completed batch executions
# TYPE atlas_completed_batches counter
atlas_completed_batches {completed_batches}

# HELP atlas_chains_available Number of chains defined in registry
# TYPE atlas_chains_available gauge
atlas_chains_available {len(registry.list_chains())}

# HELP atlas_agents_available Number of agents defined in registry
# TYPE atlas_agents_available gauge
atlas_agents_available {len(registry.list_agents())}
"""

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# CHAIN OPERATIONS
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

@app.get("/chains")
async def list_chains():
    """List all available chains."""
    chains = registry.list_chains()
    return {
        "chains": chains,
        "count": len(chains)
    }


@app.get("/chains/{chain_name}")
async def get_chain(chain_name: str):
    """Get chain definition."""
    chain = registry.get_chain(chain_name)
    if not chain:
        raise HTTPException(404, f"Chain '{chain_name}' not found")
    return {"chain": chain_name, "definition": chain}


@app.post("/execute")
async def execute_chain(request: ExecuteRequest, background_tasks: BackgroundTasks):
    """Execute a chain."""
    
    if not request.chain_name and not request.steps:
        raise HTTPException(400, "Either chain_name or steps must be provided")
    
    result = await chain_executor.execute(
        chain_name=request.chain_name,
        steps=request.steps,
        input_data=request.input,
        options=request.options
    )
    
    return {
        "intent_id": result.intent_id,
        "status": result.status.value,
        "chain_name": result.chain_name,
        "step_results": [asdict(sr) for sr in result.step_results],
        "final_output": result.final_output,
        "total_cost": result.total_cost,
        "total_duration_ms": result.total_duration_ms,
        "error": result.error
    }

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# BATCH OPERATIONS
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

@app.post("/execute-parallel")
async def execute_parallel(request: BatchExecuteRequest):
    """Execute multiple chains in parallel."""
    
    if not request.tasks:
        raise HTTPException(400, "No tasks provided")
    
    if len(request.tasks) > MAX_BATCH_SIZE:
        raise HTTPException(400, f"Maximum {MAX_BATCH_SIZE} tasks per batch")
    
    batch_id = await batch_executor.execute_batch(
        tasks=request.tasks,
        concurrency=request.concurrency,
        callback_url=request.callback_url
    )
    
    return {
        "batch_id": batch_id,
        "status": "running",
        "total_tasks": len(request.tasks),
        "concurrency": request.concurrency,
        "message": f"Batch execution started. Use /batch/{batch_id}/status to check progress."
    }


@app.get("/batch/{batch_id}/status")
async def get_batch_status(batch_id: str):
    """Get batch execution status."""
    status = batch_executor.get_batch_status(batch_id)
    if not status:
        raise HTTPException(404, f"Batch '{batch_id}' not found")
    return status


@app.get("/batch/{batch_id}/results")
async def get_batch_results(batch_id: str):
    """Get full batch results."""
    results = batch_executor.get_batch_results(batch_id)
    if not results:
        raise HTTPException(404, f"Batch '{batch_id}' not found")
    return results


@app.get("/batches")
async def list_batches(limit: int = 20, active_only: bool = False):
    """List recent batch executions."""
    batches = batch_executor.list_batches(limit=limit, active_only=active_only)
    return {
        "batches": batches,
        "count": len(batches)
    }

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# AGENT OPERATIONS
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

@app.get("/agents")
async def list_agents():
    """List all available agents."""
    agents = registry.list_agents()
    return {
        "agents": agents,
        "count": len(agents)
    }


@app.get("/agents/{agent_name}")
async def get_agent(agent_name: str):
    """Get agent definition."""
    agent = registry.get_agent(agent_name)
    if not agent:
        raise HTTPException(404, f"Agent '{agent_name}' not found")
    return {"agent": agent_name, "definition": agent}


@app.post("/call")
async def direct_call(request: DirectCallRequest):
    """Direct call to an agent (bypasses chain execution)."""
    try:
        result = await agent_caller.call(
            agent_name=request.agent,
            action=request.action,
            params=request.params
        )
        return {
            "agent": request.agent,
            "action": request.action,
            "result": result
        }
    except ValueError as e:
        raise HTTPException(404, str(e))
    except TimeoutError as e:
        raise HTTPException(504, str(e))
    except RuntimeError as e:
        raise HTTPException(502, str(e))

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# REGISTRY OPERATIONS
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

@app.post("/registry/reload")
async def reload_registry():
    """Force reload the registry."""
    registry._last_loaded = None  # Force reload
    registry.load()
    return {
        "status": "reloaded",
        "chains": len(registry.list_chains()),
        "agents": len(registry.list_agents()),
        "timestamp": datetime.utcnow().isoformat()
    }

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# LIFECYCLE
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

@app.on_event("startup")
async def startup():
    """Initialize on startup."""
    # Load registry
    registry.load()
    
    # Log startup
    try:
        async with httpx.AsyncClient() as client:
            await client.post(
                f"{EVENT_BUS_URL}/publish",
                json={
                    "event_type": "agent_started",
                    "source": "ATLAS",
                    "data": {
                        "agent": "ATLAS",
                        "port": ATLAS_PORT,
                        "version": "2.0.0",
                        "chains": len(registry.list_chains()),
                        "agents": len(registry.list_agents())
                    }
                },
                timeout=2.0
            )
    except:
        pass
    
    print(f"ðŸ›ï¸ ATLAS Orchestration Engine started on port {ATLAS_PORT}")
    print(f"   Chains: {len(registry.list_chains())}")
    print(f"   Agents: {len(registry.list_agents())}")


@app.on_event("shutdown")
async def shutdown():
    """Cleanup on shutdown."""
    await agent_caller.close()

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=ATLAS_PORT)
```

---

## Section 3: Requirements File

Create `/opt/leveredge/control-plane/agents/atlas-orchestrator/requirements.txt`:

```
fastapi>=0.104.0
uvicorn>=0.24.0
httpx>=0.25.0
pyyaml>=6.0
pydantic>=2.0
```

---

## Section 4: Systemd Service

Create `/etc/systemd/system/leveredge-atlas.service`:

```ini
[Unit]
Description=LeverEdge ATLAS Orchestration Engine
After=network.target
Wants=leveredge-event-bus.service

[Service]
Type=simple
User=root
WorkingDirectory=/opt/leveredge/control-plane/agents/atlas-orchestrator
Environment=PYTHONUNBUFFERED=1
Environment=REGISTRY_PATH=/opt/leveredge/config/agent-registry.yaml
Environment=EVENT_BUS_URL=http://localhost:8099
Environment=HERMES_URL=http://localhost:8014
ExecStart=/opt/leveredge/shared/venv/bin/python atlas.py
Restart=always
RestartSec=5
StandardOutput=journal
StandardError=journal

[Install]
WantedBy=multi-user.target
```

---

## Section 5: Update SENTINEL Configuration

Update `/opt/leveredge/control-plane/agents/griffin/sentinel.py` to use correct ATLAS URL:

```python
# Change this line:
FASTAPI_ATLAS_URL = os.getenv("FASTAPI_ATLAS_URL", "http://atlas:8007")

# To use localhost for direct connection:
FASTAPI_ATLAS_URL = os.getenv("FASTAPI_ATLAS_URL", "http://localhost:8007")
```

---

## Section 6: Update HEPHAESTUS MCP

Ensure HEPHAESTUS MCP points to correct ATLAS:

In `/opt/leveredge/control-plane/agents/hephaestus/hephaestus_mcp_server.py`:

```python
# Verify ATLAS_URL is set to port 8007
ATLAS_URL = os.getenv("ATLAS_URL", "http://localhost:8007")
```

---

## Section 7: Test Script

Create `/opt/leveredge/tests/test_atlas_orchestrator.py`:

```python
#!/usr/bin/env python3
"""
ATLAS Orchestration Engine Tests
"""

import asyncio
import httpx
import pytest

ATLAS_URL = "http://localhost:8007"


@pytest.mark.asyncio
async def test_health():
    """Test health endpoint."""
    async with httpx.AsyncClient() as client:
        response = await client.get(f"{ATLAS_URL}/health")
        assert response.status_code == 200
        data = response.json()
        assert data["status"] == "healthy"
        assert data["agent"] == "ATLAS"
        assert data["port"] == 8007


@pytest.mark.asyncio
async def test_list_chains():
    """Test listing chains."""
    async with httpx.AsyncClient() as client:
        response = await client.get(f"{ATLAS_URL}/chains")
        assert response.status_code == 200
        data = response.json()
        assert "chains" in data
        assert "count" in data
        assert data["count"] > 0  # Should have chains from registry


@pytest.mark.asyncio
async def test_list_agents():
    """Test listing agents."""
    async with httpx.AsyncClient() as client:
        response = await client.get(f"{ATLAS_URL}/agents")
        assert response.status_code == 200
        data = response.json()
        assert "agents" in data
        assert "count" in data
        assert data["count"] > 0


@pytest.mark.asyncio
async def test_direct_call():
    """Test direct agent call."""
    async with httpx.AsyncClient(timeout=30.0) as client:
        response = await client.post(
            f"{ATLAS_URL}/call",
            json={
                "agent": "chiron",
                "action": "hype",
                "params": {}
            }
        )
        # May fail if CHIRON is down, but should not 500
        assert response.status_code in [200, 502, 504]


@pytest.mark.asyncio
async def test_execute_chain():
    """Test chain execution."""
    async with httpx.AsyncClient(timeout=120.0) as client:
        response = await client.post(
            f"{ATLAS_URL}/execute",
            json={
                "chain_name": "fear-to-action",
                "input": {
                    "situation": "Testing ATLAS orchestration",
                    "avoiding": "nothing"
                }
            }
        )
        # Chain may fail if agents are down, but structure should be correct
        assert response.status_code == 200
        data = response.json()
        assert "intent_id" in data
        assert "status" in data


@pytest.mark.asyncio
async def test_batch_execution():
    """Test batch execution."""
    async with httpx.AsyncClient(timeout=10.0) as client:
        # Start batch
        response = await client.post(
            f"{ATLAS_URL}/execute-parallel",
            json={
                "tasks": [
                    {"chain_name": "fear-to-action", "input": {"situation": "Test 1"}},
                    {"chain_name": "fear-to-action", "input": {"situation": "Test 2"}}
                ],
                "concurrency": 2
            }
        )
        assert response.status_code == 200
        data = response.json()
        assert "batch_id" in data
        
        # Check status
        batch_id = data["batch_id"]
        response = await client.get(f"{ATLAS_URL}/batch/{batch_id}/status")
        assert response.status_code == 200


if __name__ == "__main__":
    asyncio.run(test_health())
    print("âœ… Health check passed")
    
    asyncio.run(test_list_chains())
    print("âœ… List chains passed")
    
    asyncio.run(test_list_agents())
    print("âœ… List agents passed")
    
    print("\nðŸ›ï¸ ATLAS basic tests passed!")
```

---

## Section 8: Deployment Script

Create `/opt/leveredge/shared/scripts/deploy-atlas.sh`:

```bash
#!/bin/bash
set -e

echo "ðŸ›ï¸ Deploying ATLAS Orchestration Engine..."

# Create directory
mkdir -p /opt/leveredge/control-plane/agents/atlas-orchestrator

# Install dependencies
cd /opt/leveredge/control-plane/agents/atlas-orchestrator
/opt/leveredge/shared/venv/bin/pip install -r requirements.txt

# Install systemd service
sudo cp /opt/leveredge/specs/leveredge-atlas.service /etc/systemd/system/
sudo systemctl daemon-reload
sudo systemctl enable leveredge-atlas
sudo systemctl restart leveredge-atlas

# Wait for startup
sleep 3

# Check health
if curl -s http://localhost:8007/health | grep -q "healthy"; then
    echo "âœ… ATLAS is healthy!"
else
    echo "âŒ ATLAS health check failed"
    sudo journalctl -u leveredge-atlas -n 50
    exit 1
fi

# Show status
curl -s http://localhost:8007/status | python3 -m json.tool

echo ""
echo "ðŸ›ï¸ ATLAS Orchestration Engine deployed successfully!"
echo "   Port: 8007"
echo "   Health: http://localhost:8007/health"
echo "   Chains: http://localhost:8007/chains"
echo "   Agents: http://localhost:8007/agents"
```

---

## Section 9: Integration with ARIA Knowledge

After deployment, add to ARIA knowledge:

```sql
INSERT INTO aria_knowledge (category, key, value, source)
VALUES (
    'infrastructure',
    'atlas_orchestrator_deployed',
    'ATLAS Orchestration Engine v2.0 deployed on port 8007. Executes chains from agent-registry.yaml, handles parallel batch processing, tracks costs. SENTINEL routes through ATLAS for all orchestration.',
    'gsd-build-orchestration-atlas'
);
```

---

## Section 10: Verification Checklist

After deployment, verify:

```bash
# 1. Health check
curl http://localhost:8007/health

# 2. List chains (should show 6 chains)
curl http://localhost:8007/chains

# 3. List agents (should show all agents from registry)
curl http://localhost:8007/agents

# 4. Test SENTINEL routing
curl http://localhost:8006/status

# 5. Test HEPHAESTUS MCP orchestrate
# (via Claude Code)

# 6. Run test suite
cd /opt/leveredge
python tests/test_atlas_orchestrator.py
```

---

## Execution Order

1. **Create directory structure** (Section 1)
2. **Create atlas.py** (Section 2)
3. **Create requirements.txt** (Section 3)
4. **Create systemd service** (Section 4)
5. **Update SENTINEL** (Section 5)
6. **Update HEPHAESTUS MCP** (Section 6)
7. **Create test script** (Section 7)
8. **Run deployment script** (Section 8)
9. **Update ARIA knowledge** (Section 9)
10. **Run verification** (Section 10)

---

## GSD Command

```
/gsd /opt/leveredge/specs/gsd-build-orchestration-atlas.md

CONTEXT: ATLAS (port 8007) doesn't exist - it's been missing this whole time. 
The code at /control-plane/agents/atlas/ is actually ATLAS-INFRA (port 8208).
This is why "ATLAS keeps going offline" - there's nothing there.

CRITICAL NOTES:
- Create NEW directory: /control-plane/agents/atlas-orchestrator/
- Port 8007 is the orchestration engine
- Read chains from /opt/leveredge/config/agent-registry.yaml
- Use the shared venv at /opt/leveredge/shared/venv
- SENTINEL expects ATLAS at http://localhost:8007
- After deployment, verify with curl http://localhost:8007/health

MCP REMINDER: Use n8n-control MCP for any workflow changes.
```

---

## Expected Outcome

After completion:
- **ATLAS running on port 8007** with health endpoint responding
- **6 chains available** from agent-registry.yaml
- **SENTINEL successfully routing** to ATLAS
- **HEPHAESTUS MCP orchestrate tool working**
- **Parallel batch processing** for multiple chains
- **Cost tracking** per execution
- **No more "ATLAS offline" errors**

---

## Total Estimated Time: 4-6 hours

- Directory setup: 5 min
- Core ATLAS code: Already written above (copy/paste)
- Testing: 30 min
- Integration fixes: 1 hour
- Debugging: 1-2 hours
- Verification: 30 min
